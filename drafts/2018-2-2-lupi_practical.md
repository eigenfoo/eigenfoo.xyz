---
mathjax: true
title: ~~Fruit~~ Loops and Learning 2 - Problems with LUPI
excerpt: "Problems with LUPI and SVM+"
header:
  teaser: /assets/images/loops.jpeg
  overlay_image: /assets/images/loops.jpeg
  caption: "Photo credit: [wallpapercraze.com](http://wallpapercraze.com/images/wallpapers/fruitloops-441535.jpeg)"
  last_modified_at: 2018-02-02
---

In my last post, I introduced the LUPI paradigm and described one algorithm that
adheres to that paradigm: SVM+. I described LUPI as a nascent perspective on
machine learning that had great potential.

In this post, I'll describe some reasons why LUPI might not be so great, and
some important reasons not to immediately rush to apply SVM+. Most of my
comments here will be based on [this
paper](https://www.sciencedirect.com/science/article/pii/S0167865514000270) by
Serra-Toro et al.

---

## So what's up?

In a nutshell, Serra-Toro's main finding is that "just using randomly generated
features as privileged information may perform similarly to using sensible (i.e.
meaningful a priori) privileged information, at least in some problems".



